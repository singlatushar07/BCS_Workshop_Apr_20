{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CM.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "zqyF7YqKLBNE",
        "i9dvgCQ8K2JG",
        "mSAQJesjLIVS",
        "drTdC-wkOC3x",
        "5BG8yOdIFjlC",
        "YTuXvQeLS5rs",
        "XKCugacP96PA",
        "rNR0tNn782Fg"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kM8pug2G1oNl",
        "colab_type": "text"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/bcs-iitk/BCS_Workshop_Apr_20/blob/master/Computational_Modeling/Assignment/CM.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/bcs-iitk/BCS_Workshop_Apr_20/blob/master/Computational_Modeling/Assignment/CM.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://github.com/bcs-iitk/BCS_Workshop_Apr_20/raw/master/Computational_Modeling/Assignment/CM.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4Rwmt7Yh7tg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copyright (c) 2020 Brain and Cognitive Society, IIT Kanpur [ BCS @IITK ]\n",
        "# Copyright under MIT License, must reference https://github.com/bcs-iitk/BCS_Workshop_Apr_20 if used anywhere else.\n",
        "# Author: Shashi Kant (http://shashikg.github.io/)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G94-blqD12J9",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 2: Computational Modeling\n",
        "I hope you guys have gone through the videos, the purpose of first three videos was to teach you about why we build computational model and what it is and how in general we do it. The videos provided after that introduced you to some of the remarkable models of cognition from a historical perspective. In this assignment we will try to build those model computationaly in python. Before going further let me give you a basic gist about how computational modeling is done so as to make it sure that you understood it. So computational modeling basically involves following steps:\n",
        "\n",
        "* First we study human cognition using some experiments (any psychological or neuro experiment).\n",
        "* Record human behavior on the given set of stimuli designed for the experiments.\n",
        "* Based on those behavior conclude some idea about the cognitive processes.\n",
        "* Then we build a computaional model of that.\n",
        "* After that we feed the same stimuli to our computational model and predict behavior.\n",
        "* finally we verify if our model is predicting the same behavior.\n",
        "\n",
        "Overall we follow the following process:\n",
        "<img src=\"https://raw.githubusercontent.com/bcs-iitk/BCS_Workshop_Apr_20/master/Computational_Modeling/Assignment/cm.png\" width=\"90%\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CT2oIc-yKzG2",
        "colab_type": "text"
      },
      "source": [
        "## Question 1: Model of Memory: Atkinson-Shiffrin's Multi-Store Model of Memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqyF7YqKLBNE",
        "colab_type": "text"
      },
      "source": [
        "### Description of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWOteKG73It9",
        "colab_type": "text"
      },
      "source": [
        "Recall about Atkinson-Shiffrin's Multi-Store Model of Memory and Serial Position Effect. In this part of the assignment we will try to build that model of memory and will verify it using the serial position effect.\n",
        "<img src=\"https://raw.githubusercontent.com/bcs-iitk/BCS_Workshop_Apr_20/master/Computational_Modeling/Assignment/memory.png\" width=\"90%\">\n",
        "\n",
        "While building this model we will make following assumptions:\n",
        "* Sensory Memory:\n",
        " * Only those information, which should be attended will be forwarded to STM.\n",
        " * Whether an information should be attended or not will be given.\n",
        "\n",
        "* Short Term Memory (STM):\n",
        " * Holds an item for **20 sec** if its not rehearsed.\n",
        " * Capacity of max **7 items**\n",
        " * Rehearsal properties:\n",
        "   * Only those item will be rehearsed which is to be remembered or learned.\n",
        "   * Whether the item will be stored in LTM or not will depend on its **rehearsal count (RC)**.\n",
        "   * Randomly decide to store the item to LTM based on the follwing probablity:  $sigmoid(\\frac{RC-3150}{630})$. Where; $sigmoid(x) = \\frac{1}{1+exp(-x)}$ (There is no evidence for this probability rule, selected arbitrarily)\n",
        "   * This rehearsal count for each item will be calculated on the basis of **rehearsal speed of STM.**\n",
        "   * The rehearsal speed of STM will depend on the number of rehearsable item i.e items which are to be remembered.\n",
        "   * Such that, **rehearsal speed (RS) = (420/num_rehearsable_items)/sec**\n",
        "   * Therefore, **RC = RS*time**\n",
        " * If STM contains 7 items and a new item comes, following will happen:\n",
        "   * If there are any non-rehearsable item, then it will be removed from STM store and will be replaced by the new item (process is called as Displacement). \n",
        "   * If all items are rehearsable, an item will be removed randomly based on equal probality for each item and will be replaced by the new item.\n",
        "   * Before dumping the removed item it will be checked if it should be kept in LTM or not based on the rehearsal property mentioned above.\n",
        "* Long Term Memory (LTM):\n",
        " * Infinite capacity for infinite time.\n",
        "\n",
        "Now lets start modeling it!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9dvgCQ8K2JG",
        "colab_type": "text"
      },
      "source": [
        "### Creating the model of the memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4WmUcZt1ygx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy.random import choice as randC\n",
        "from numpy.random import uniform as randU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98-yVmqj28En",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MemoryModel:\n",
        "  class SensoryMemory:\n",
        "    def __init__(self, attention_store):\n",
        "      '''\n",
        "      Arguments:\n",
        "      attention_store - python list\n",
        "      '''\n",
        "      self.attention_store = attention_store\n",
        "\n",
        "    def input(self, item):\n",
        "      '''\n",
        "      Implement this function to check if the input item should be attended or not.\n",
        "      If the item is in self.attention_filter then it should be attended otherwise rejected\n",
        "      Should return True if attended otherwise False\n",
        "      Use attn_flag variable to store your True or False value\n",
        "      '''\n",
        "\n",
        "      ## Start your code here >>>>>>>>>>>>>>>>>>>>>>>\n",
        "      \n",
        "      ## End your code here >>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "\n",
        "      return attn_flag\n",
        "\n",
        "  class STM:\n",
        "    def __init__(self, capacity=7, duration=20):\n",
        "      self.capacity = capacity\n",
        "      self.duration = duration\n",
        "      self.max_rehearsal_speed = 420.0\n",
        "      self.store = []                 # 'pytho list': this should contain the items stored in STM \n",
        "      self.rehearsal_flag = []        # 'pytho list': this should contain 0 for non rehearsalable item and 1 for rehearsable item.\n",
        "      self.rehearsal_count = []       # 'pytho list': this should contain the rehearsal count performed by respective items\n",
        "      self.last_update_time = 0       #  last time the memory was updated\n",
        "      self.input_time = []            # 'pytho list': input time of the item\n",
        "\n",
        "    def input(self, item, time, LTM_Link, r_flag=0):\n",
        "      '''\n",
        "      Implement this function to achieve the task of the input processing of STM\n",
        "      Should do the following function:\n",
        "       - Check if the number of items currently present in STM i.e. length of self.store\n",
        "       - If numbers of items are 7, forget one item using the condition described above.\n",
        "       - Store the removed item in LTM using \"LTM_Link\" decide using the probability given above. [Hint: LTM_Link.input(item)]\n",
        "       - Store the new item in self.store and its rehearsable flag \"r_flag\" in self.rehearsal_flag and intialise its rehearsal_count to \"0\"\n",
        "       - Store the current time \"time\" into self.input_time at respective position of new item\n",
        "      \n",
        "      Arguments:\n",
        "      item - the input item which is to be stored\n",
        "      r_flag - rehearsable flag\n",
        "      LTM_Link - var linking the LTM of the memory\n",
        "      time - current time\n",
        "      '''\n",
        "\n",
        "      ## Start your code here >>>>>>>>>>>>>>>>>>>>>>>\n",
        "\n",
        "      ## End your code here >>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "\n",
        "      return\n",
        "\n",
        "    def retrieve(self):\n",
        "      '''\n",
        "      Implement this function to retrieve the item stored in short term memory\n",
        "\n",
        "      Return:\n",
        "      items - List of item stored in STM\n",
        "      '''\n",
        "\n",
        "      ## Start your code here >>>>>>>>>>>>>>>>>>>>>>>\n",
        "      \n",
        "      ## End your code here >>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "\n",
        "      return items\n",
        "\n",
        "    def update(self, time, LTM_Link):\n",
        "      '''\n",
        "      Implement this function to update the items stored in STM.\n",
        "      Should do the following functions:\n",
        "       - for rehearsable items update self.rehearsal_count of each items using the current time \"time\" and self.last_update_time\n",
        "       - note extra count should be added to the previous one.\n",
        "       - for non rehearsable item its rehearsal_count will remain zeros\n",
        "       - update self.input_time for all rehearsable item to current time \"time\" (because the item is rehearsed)\n",
        "       - update self.last_update_time\n",
        "       - If any non rehearsable item's storage duration becomes >= self.duration, remove that element from self.store\n",
        "       - Store the removed item in LTM using \"LTM_Link\" decide using the probability given above.\n",
        "\n",
        "      '''\n",
        "\n",
        "      ## Start your code here >>>>>>>>>>>>>>>>>>>>>>>\n",
        "\n",
        "      ## End your code here >>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "\n",
        "      return\n",
        "\n",
        "    def stop_rehearsal(self):\n",
        "      '''\n",
        "      set rehearsal_flag of all the item to \"0\"\n",
        "      '''\n",
        "\n",
        "      ## Start your code here >>>>>>>>>>>>>>>>>>>>>>>\n",
        "      \n",
        "      ## End your code here >>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "\n",
        "      return\n",
        "\n",
        "  class LTM:\n",
        "    def __init__(self):\n",
        "      self.store = []\n",
        "\n",
        "    def input(self, item):\n",
        "      '''\n",
        "      This function should store the new item into LTM store i.e. self.store\n",
        "      '''\n",
        "\n",
        "      ## Start your code here >>>>>>>>>>>>>>>>>>>>>>>\n",
        "      \n",
        "      ## End your code here >>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "\n",
        "      return\n",
        "\n",
        "    def retrieve(self):\n",
        "      '''\n",
        "      Implement this function to retrieve the item stored in long term memory\n",
        "\n",
        "      Return:\n",
        "      items - List of item stored in LTM\n",
        "      '''\n",
        "\n",
        "      ## Start your code here >>>>>>>>>>>>>>>>>>>>>>>\n",
        "      \n",
        "      ## End your code here >>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "\n",
        "      return items\n",
        "\n",
        "  def __init__(self, attention_store, capacity=7, duration=20):\n",
        "    self.SM_Link = self.SensoryMemory(attention_store=attention_store)\n",
        "    self.STM_Link = self.STM(capacity=7, duration=20)\n",
        "    self.LTM_Link = self.LTM()\n",
        "\n",
        "  def input(self, item, time, remember=False):\n",
        "    attn_flag = self.SM_Link.input(item)\n",
        "\n",
        "    if attn_flag:\n",
        "      self.STM_Link.update(time, self.LTM_Link)\n",
        "      self.STM_Link.input(item, time, self.LTM_Link, int(remember))\n",
        "\n",
        "  def retrieve(self, time):\n",
        "    self.STM_Link.update(time, self.LTM_Link)\n",
        "    STM_items = self.STM_Link.retrieve()\n",
        "    LTM_items = self.LTM_Link.retrieve()\n",
        "\n",
        "    return list(STM_items) + list(LTM_items)\n",
        "\n",
        "  def stop_rehearsal(self):\n",
        "    self.STM_Link.stop_rehearsal()\n",
        "\n",
        "  def erase(self):\n",
        "    '''\n",
        "    To forget all the stored items\n",
        "    '''\n",
        "    self.STM_Link = STM(capacity=7, duration=20)\n",
        "    self.LTM_Link = LTM()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSAQJesjLIVS",
        "colab_type": "text"
      },
      "source": [
        "### Testing the memory model\n",
        "To test the basic working of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_VH2qPEJ4D6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attention_store = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\n",
        "\n",
        "memory = MemoryModel(attention_store, capacity=7, duration=20)\n",
        "\n",
        "input_data = ['B', 'A', 'C', 'E', 'F', 'R']\n",
        "remember_flag = [False, True, False, False, True, True]\n",
        "input_time = [0, 5, 10, 15, 20, 25]\n",
        "\n",
        "for i in range(len(input_data)):\n",
        "  memory.input(input_data[i], input_time[i], remember=remember_flag[i])\n",
        "\n",
        "print(\"\\nRecall at time 30 secs:\") # test of STM duration\n",
        "print(memory.retrieve(30))\n",
        "\n",
        "memory.stop_rehearsal()\n",
        "print(\"\\nRecall at time 40 secs:\") # test of STM rehearsal\n",
        "print(memory.retrieve(40))\n",
        "\n",
        "memory.stop_rehearsal()\n",
        "print(\"\\nRecall at time 50 secs:\") # test of LTM\n",
        "print(memory.retrieve(50))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEXq4B-Vn1Xd",
        "colab_type": "text"
      },
      "source": [
        "Expected output:\n",
        "\n",
        "\n",
        "```\n",
        "Recall at time 30 secs:\n",
        "['A', 'E', 'F']\n",
        "\n",
        "Recall at time 40 secs:\n",
        "['A', 'F']\n",
        "\n",
        "Recall at time 50 secs:\n",
        "['A']\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drTdC-wkOC3x",
        "colab_type": "text"
      },
      "source": [
        "### Serial position effect experiment\n",
        "Testing the serial position effect experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdTA-oLhiTb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data_spe():\n",
        "  !wget --no-verbose --no-check-certificate https://github.com/bcs-iitk/BCS_Workshop_Apr_20/raw/master/Computational_Modeling/Assignment/data/memory/stimuli.npy -O stimuli.npy\n",
        "  !wget --no-verbose --no-check-certificate https://github.com/bcs-iitk/BCS_Workshop_Apr_20/raw/master/Computational_Modeling/Assignment/data/memory/remember_flag.npy -O remember_flag.npy\n",
        "  !wget --no-verbose --no-check-certificate https://github.com/bcs-iitk/BCS_Workshop_Apr_20/raw/master/Computational_Modeling/Assignment/data/memory/input_time.npy -O input_time.npy\n",
        "  !wget --no-verbose --no-check-certificate https://github.com/bcs-iitk/BCS_Workshop_Apr_20/raw/master/Computational_Modeling/Assignment/data/memory/attention_store.npy -O attention_store.npy\n",
        "\n",
        "  stimuli = np.load(\"stimuli.npy\")\n",
        "  remember_flag = np.load(\"remember_flag.npy\")\n",
        "  input_time = np.load(\"input_time.npy\")\n",
        "  attention_store = np.load(\"attention_store.npy\")\n",
        "\n",
        "  return attention_store, stimuli, remember_flag, input_time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LISq3Xe94shv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attention_store, stimuli, remember_flag, input_time = load_data_spe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bJOY05m4xoZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_single_exp(attention_store, input_data, remember_flag, input_time):\n",
        "  ''' \n",
        "  Implement this function to run the experiment on a single stimuli. \n",
        "  Use help from the model testing example.\n",
        "  model should retrieve the stored item at time = input_time[-1] + 1\n",
        "\n",
        "  Arguments:\n",
        "  attention_store - python list of items which are allowed to attend\n",
        "  input_data - python list of input items (subset of attenstion store)\n",
        "  remember_flag - python list of remember flag i.e. whether the input item allowed to rehearse or not; for this exp all are True.\n",
        "  input_time - python list of time at which input data are fed. intervals of 5 secs.\n",
        "\n",
        "  Return:\n",
        "  recall_idx - numpy array of size equal to the length of input_data, \n",
        "               if the item at index 'i' i.e. input_data[i] is sucessfully recalled recall_idx[i] = 1 otherwise 0\n",
        "               Hint: use a.index(item) to find the index of an item in a list s.\n",
        "  '''\n",
        "\n",
        "  ## Start your code here >>>>>>>>>>>>>>>>>>>>>>>\n",
        "\n",
        "  ## End your code here >>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "\n",
        "  return recall_idx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCphPbTZ8YB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run the experiment for all stimuli set and plot average\n",
        "\n",
        "recall_perc = np.zeros(stimuli.shape[1])\n",
        "N = stimuli.shape[0]\n",
        "\n",
        "for i in range(N):\n",
        "  recall_perc += run_single_exp(list(attention_store), list(stimuli[i]), list(remember_flag[i]), list(input_time[i]))\n",
        "\n",
        "recall_perc /= N/100\n",
        "\n",
        "plt.plot(recall_perc, 'o-r')\n",
        "plt.ylabel('Percent recalled')\n",
        "plt.xlabel('Serial position')\n",
        "plt.grid()\n",
        "plt.title(\"Serial-position curve\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXI266a4BSuO",
        "colab_type": "text"
      },
      "source": [
        "Expected output: (Not exact but pattern should be more or like this)\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/bcs-iitk/BCS_Workshop_Apr_20/master/Computational_Modeling/Assignment/spc.png\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiaP-l7qFNa0",
        "colab_type": "text"
      },
      "source": [
        "## Question 2: Model of Attention: Feature Integration Theory (FIT)\n",
        "In this part, we will try to build the computational model of attention based on feature integration theory. After building the model, we will verify it on the two kinds of visual search task i.e. parallel (feature) search and serial (conjunction) search."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BG8yOdIFjlC",
        "colab_type": "text"
      },
      "source": [
        "### Description of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7WG5szVFosr",
        "colab_type": "text"
      },
      "source": [
        "Lets briefly recall what features integration theory says. So according FIT when perceiving a visual stimulus, basic features such as color, shape, motion, depth, etc are attended early in the process, automatically and parallel. Parallel means all the features across the whole image is identified simultaneously. While the complete objects are identified in the later stage of processing which combines these features to finally define the object. So this combining of features is done serially.\n",
        " \n",
        "![FIT](https://4.bp.blogspot.com/-iBYucws87tM/Thu7A_DLMEI/AAAAAAAAAAQ/GANIhYmUSVk/s1600/FIT.gif)\n",
        "\n",
        "The whole process can be broken down into following steps:\n",
        "* Stimulus input,\n",
        "* Preattentive Stage:\n",
        "  * Creation of feature maps for different basic features, for simplicity we will create feature maps for just two kinds of features i.e. color and shape.\n",
        "  * So, in this stage model will find the location of the features of the target image present in the search image.\n",
        "* Focused Attention Stage::\n",
        "  * In this stage, a master map of location is created based on combining all the feature maps, you get a single map which gives the location on the search image where different features have been detected.\n",
        "* Perception of the object.\n",
        "\n",
        "#### Feature (Parallel) Search:\n",
        "In this kind of visual search, target is defined only by only one feature i.e. color or shape. Therefore, these are fast and are done pre-attentivly directly using the feature map.\n",
        "\n",
        "#### Conjunction (Serial) Search:\n",
        "In this kind of visual search, target is defined by multiple features and are identified serially. Therefore, these are slow and are done using the master map of location.\n",
        "\n",
        "<img src=\"https://slideplayer.com/slide/16537272/96/images/16/Visual+search+X+X+X+X+O+X+O+X+X+X+X+X+X+O+X+X+X+X+O+O+X+X+O+X+X+X+X.jpg\" width=\"80%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTuXvQeLS5rs",
        "colab_type": "text"
      },
      "source": [
        "### Creating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t0BV--BFZDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy.random import choice as randC\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wmo_MiQgulxc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#####################################\n",
        "##   Do not touch this part        ##\n",
        "##   This has been done for you    ##\n",
        "#####################################\n",
        "\n",
        "def get_color_map(search_img, tar_img, grid_size=(5, 5), grid_length=30):\n",
        "  img_rgb = np.copy(tar_img)\n",
        "  img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
        "  thresh = cv2.adaptiveThreshold(img_gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,11,2)\n",
        "  ret,thresh = cv2.threshold(img_gray,160,255,0)\n",
        "  contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "  M = cv2.moments(contours[1])\n",
        "  cx = int(M['m10']/M['m00'])\n",
        "  cy = int(M['m01']/M['m00'])\n",
        "\n",
        "  th_val = cv2.cvtColor(img_rgb[cx, cy].reshape((1, 1, 3)), cv2.COLOR_BGR2GRAY)\n",
        "  th_val = th_val.reshape(1)\n",
        "\n",
        "  img_rgb = np.copy(search_img)\n",
        "  img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
        "  ret,th1 = cv2.threshold(img_gray,th_val[0]-5,255,0)\n",
        "  ret,th2 = cv2.threshold(img_gray,th_val[0]+5,255,0)\n",
        "  thresh = th2-th1\n",
        "  contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "  c_map = np.zeros(grid_size)\n",
        "\n",
        "  for cnt in contours:\n",
        "    M = cv2.moments(cnt)\n",
        "    cy = int(M['m10']/M['m00'])\n",
        "    cx = int(M['m01']/M['m00'])\n",
        "\n",
        "    c_map[int(cx/grid_length), int(cy/grid_length)] = 1\n",
        "\n",
        "  return c_map\n",
        "\n",
        "#####################################\n",
        "##   Do not touch this part        ##\n",
        "##   This has been done for you    ##\n",
        "#####################################\n",
        "\n",
        "def get_shape_map(search_img, tar_img, grid_size=(5, 5), grid_length=30):\n",
        "  img_rgb = np.copy(search_img)\n",
        "  img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
        "  template = cv2.cvtColor(tar_img, cv2.COLOR_BGR2GRAY)\n",
        "  w, h = template.shape[::-1]\n",
        "\n",
        "  res = cv2.matchTemplate(img_gray,template,cv2.TM_CCOEFF_NORMED)\n",
        "  threshold = 0.99\n",
        "  loc = np.where( res >= threshold)\n",
        "\n",
        "  s_map = np.zeros(grid_size)\n",
        "\n",
        "  for pt in zip(*loc[::-1]):\n",
        "    cx, cy = (int((pt[1]+grid_length/3)/grid_length), int((pt[0]+grid_length/3)/grid_length))\n",
        "    s_map[cx, cy] = 1\n",
        "\n",
        "  return s_map\n",
        "\n",
        "#####################################\n",
        "##   Do not touch this part        ##\n",
        "##   This has been done for you    ##\n",
        "#####################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcYlp1JMTFLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FIT:\n",
        "  def __init__(self, grid_size=(5, 5), grid_length=30):\n",
        "    self.map_size = grid_size\n",
        "    self.grid_length = grid_length\n",
        "    self.color_map = np.zeros(grid_size)\n",
        "    self.shape_map = np.zeros(grid_size)\n",
        "    self.master_map = np.zeros(grid_size)\n",
        "    self.fxn2ms = 320 # approximate value to convert fixation number to millisec\n",
        "\n",
        "  def reset_maps(self):\n",
        "    '''\n",
        "    This should reset all the maps to zeros\n",
        "    '''\n",
        "\n",
        "    ## Start your code here >>>>>>>>>>>>>>>>>>>>>>>\n",
        "\n",
        "    ## End your code here >>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "\n",
        "    return\n",
        "\n",
        "  def gen_feature_map(self, search_img, tar_img):\n",
        "    '''\n",
        "    Generate the feature maps i.e. self.color_map and self.shape_map using the function get_color_map() and get_shape_map()\n",
        "    '''\n",
        "\n",
        "    ## Start your code here >>>>>>>>>>>>>>>>>>>>>>>\n",
        "\n",
        "    ## End your code here >>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "\n",
        "    return\n",
        "\n",
        "  def gen_master_map(self):\n",
        "    '''\n",
        "    Implement this function to generate the master_map in self.master_map\n",
        "    self.master_map - should be the overall attention map i.e. '1' at the places where features where detected. \n",
        "    doesn't matter if its a shape feature or color feature.\n",
        "    '''\n",
        "\n",
        "    ## Start your code here >>>>>>>>>>>>>>>>>>>>>>>\n",
        "\n",
        "    ## End your code here >>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "\n",
        "    return\n",
        "\n",
        "  def visual_search(self, search_img, tar_img):\n",
        "    '''\n",
        "    Implement this function to perform the visual search task\n",
        "    Should do the following things:\n",
        "     - at first reset the feature map and master map \n",
        "     - gen_feature_map\n",
        "     - check if there is single object in any of the feature map? If yes, no need to attend and create attention map | Hint: single => only one position with value = '1'\n",
        "       simply return the grid index of the target and reaction_time; reaction_time = fxn_number*self.fxn2ms | Hint: in this case take fxn_number = 1\n",
        "     - If single object is not in both feature maps =>> It's conjunction search, gen the master map integrating both features.\n",
        "     - Now, randomly select the points in master_map which have value = '1' i.e. the places were the model will attend to recognise object.\n",
        "       At each attended position check if both features are present or not?\n",
        "     - Keep this running in a loop till you find the object position i.e. where both features are present.\n",
        "     - Note: do not visit the same position again, do not visit the position which have value = '0'\n",
        "     - Also, count the total number of iterations it took to find the object, and take that as the fxn_number.\n",
        "     - Return the grid_idx and reaction_time\n",
        "\n",
        "    Return:\n",
        "    RT - reaction time = fxn_number*self.fxn2ms\n",
        "    tar_idx = position of the target object\n",
        "    '''\n",
        "\n",
        "    ## Start your code here >>>>>>>>>>>>>>>>>>>>>>>\n",
        "\n",
        "    ## End your code here >>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "\n",
        "    return tar_idx, RT"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKCugacP96PA",
        "colab_type": "text"
      },
      "source": [
        "### Load visual search data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZe8mh0C86bd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data_vs():\n",
        "  !wget --no-verbose --no-check-certificate https://github.com/bcs-iitk/BCS_Workshop_Apr_20/raw/master/Computational_Modeling/Assignment/data/fit/conjunction_search_img.npy -O conjunction_search_img.npy\n",
        "  !wget --no-verbose --no-check-certificate https://github.com/bcs-iitk/BCS_Workshop_Apr_20/raw/master/Computational_Modeling/Assignment/data/fit/conjunction_target_img.npy -O conjunction_target_img.npy\n",
        "  !wget --no-verbose --no-check-certificate https://github.com/bcs-iitk/BCS_Workshop_Apr_20/raw/master/Computational_Modeling/Assignment/data/fit/feature_search_img.npy -O feature_search_img.npy\n",
        "  !wget --no-verbose --no-check-certificate https://github.com/bcs-iitk/BCS_Workshop_Apr_20/raw/master/Computational_Modeling/Assignment/data/fit/feature_target_img.npy -O feature_target_img.npy\n",
        "\n",
        "  conjunction_search_img = np.load(\"conjunction_search_img.npy\")\n",
        "  conjunction_target_img = np.load(\"conjunction_target_img.npy\")\n",
        "  feature_search_img = np.load(\"feature_search_img.npy\")\n",
        "  feature_target_img = np.load(\"feature_target_img.npy\")\n",
        "\n",
        "  return conjunction_search_img, conjunction_target_img, feature_search_img, feature_target_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndMamnmo9re5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conjunction_search_img, conjunction_target_img, feature_search_img, feature_target_img = load_data_vs()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNR0tNn782Fg",
        "colab_type": "text"
      },
      "source": [
        "### Run Visual Search\n",
        "Here, we will test our model on the visual search stimuli."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8caZs0NSAIqM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_visual_search_exp(search_stimuli, tar_img, grid_size=(5, 5), grid_length=30):\n",
        "  '''\n",
        "  Implement this function to run the visual search experiment on 60 stimuli\n",
        "\n",
        "  Attribute:\n",
        "  search_stimuli - (60, 150, 150, 3) numpy array with set of 60 search images of size (150, 150, 3)\n",
        "                 - images between (0, 20) index have total '7' objects in the search images; objects means target plus distractors\n",
        "                 - images between (20, 40) index have total '14' objects in the search images\n",
        "                 - images between (40, 60) index have total '21' objects in the search images\n",
        "\n",
        "  tar_img - (30, 30, 3) numpy array, contains target image, same target image for all the search images.\n",
        "\n",
        "  Return:\n",
        "  RT - python list having 3 elements\n",
        "     - RT[0] = average reaction time for search images having '7' objects\n",
        "     - RT[1] = average reaction time for search images having '14' objects\n",
        "     - RT[2] = average reaction time for search images having '21' objects\n",
        "  '''\n",
        "\n",
        "  ## Start your code here >>>>>>>>>>>>>>>>>>>>>>>\n",
        "\n",
        "  ## End your code here >>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "\n",
        "  return RT"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0J51tgL9yP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Displaying images\n",
        "plt.figure()\n",
        "plt.imshow(feature_search_img[45])\n",
        "plt.title(\"Feature - Search Image\")\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(conjunction_search_img[45])\n",
        "plt.title(\"Conjunction - Search Image\")\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(feature_target_img)\n",
        "plt.title(\"Target Image\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hnz2i6Tp-TYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "set_size = [7, 14, 21]\n",
        "RT_C = run_visual_search_exp(conjunction_search_img, conjunction_target_img, grid_size=(5, 5), grid_length=30)\n",
        "RT_F = run_visual_search_exp(feature_search_img, feature_target_img, grid_size=(5, 5), grid_length=30)\n",
        "\n",
        "plt.plot(set_size, RT_F, 'o-r', label=\"Feature Search\")\n",
        "plt.plot(set_size, RT_C, 'o-b', label=\"Conjunction Search\")\n",
        "plt.ylabel('Reaction time (ms)')\n",
        "plt.xlabel('Set size')\n",
        "plt.legend(loc='upper left')\n",
        "plt.grid()\n",
        "plt.title(\"Visual Search\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL2SHHE0UhDu",
        "colab_type": "text"
      },
      "source": [
        "Expected output: (Not exact but pattern should be more or like this)\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/bcs-iitk/BCS_Workshop_Apr_20/master/Computational_Modeling/Assignment/vs.png\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXtfLW1JR0qB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}