{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ML.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPffDXWPf7sDUd9XWqUmhTa"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"xgTHW1jTc94u","colab_type":"text"},"source":["<table class=\"tfo-notebook-buttons\" align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/github/bcs-iitk/BCS_Workshop_Apr_20/blob/master/Machine_Learning/Assignment/ML.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://github.com/bcs-iitk/BCS_Workshop_Apr_20/blob/master/Machine_Learning/Assignment/ML.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n","  </td>\n","  <td>\n","    <a href=\"https://github.com/bcs-iitk/BCS_Workshop_Apr_20/raw/master/Machine_Learning/Assignment/ML.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n","  </td>\n","</table>"]},{"cell_type":"code","metadata":{"id":"BiU-x0ujcRkE","colab_type":"code","colab":{}},"source":["# Copyright (c) 2020 Brain and Cognitive Society, IIT Kanpur [ BCS @IITK ]\n","# Copyright under MIT License, must reference https://github.com/bcs-iitk/BCS_Workshop_Apr_20 if used anywhere else.\n","# Author: Shashi Kant (http://shashikg.github.io/)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-6GMP27JdNG2","colab_type":"text"},"source":["\n","\n","> Note: Do not forget to click on **Copy to Drive** in Google Colab to save a copy of this assignment.\n","\n","![copy2drive](https://github.com/bcs-iitk/BCS_Workshop_Apr_20/raw/master/Machine_Learning/Assignment/copy2drive.png)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"UWRTh7z2ZmM2","colab_type":"text"},"source":["# Assignment 1: Machine Learning\n"]},{"cell_type":"markdown","metadata":{"id":"UkJr6Lh9aIem","colab_type":"text"},"source":["## Question 1: Linear Regression\n","To check whether you are able to build simple linear regression model from scratch or not."]},{"cell_type":"code","metadata":{"id":"wq1ZliSEuhTw","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","!wget --no-check-certificate https://github.com/bcs-iitk/BCS_Workshop_Apr_20/raw/master/Machine_Learning/Assignment/X.npy -O X.npy\n","!wget --no-check-certificate https://github.com/bcs-iitk/BCS_Workshop_Apr_20/raw/master/Machine_Learning/Assignment/y.npy -O y.npy"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"021fTYdwTkZm","colab_type":"code","colab":{}},"source":["def load_data_LR():\n","  # Implement this function to read the dataset using the path declared in path_X and path_y\n","  # should return the X and y data\n","  # use np.load() to load the data google it you will get to know how to do it\n","\n","  path_X = \"X.npy\"\n","  path_y = \"y.npy\"\n","\n","  # Write your code here ----------\n","\n","  # -------------------------------\n","\n","  return X, y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ngg3QUyTfBxC","colab_type":"code","colab":{}},"source":["def get_linear_model(X, y):\n","  # This shoudl return a proper linear model without bias of type y = XW\n","\n","  # Write your code here ----------\n","  \n","  # -------------------------------\n","  \n","  W = np.random.randn(D, out_shape)\n","\n","  return W"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c52FIGu-hlzM","colab_type":"code","colab":{}},"source":["def MSE(y, y_pred):\n","  # should return the mean square error between the actual y and predicted y\n","\n","  # Write your code here ----------\n","  \n","  # -------------------------------\n","\n","  return error"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zrBrqA15hCdT","colab_type":"code","colab":{}},"source":["def train_by_algebra(X, y):\n","  # should return the trained weight 'W' using the linear algebra method i.e. setting dE/dW = 0\n","\n","  # Write your code here ----------\n","  \n","  # -------------------------------\n","\n","  return W"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kJ_r_R1PixX2","colab_type":"code","colab":{}},"source":["def train_by_GD(X, y, epochs=5, lr=0.01):\n","  # should return the trained weight 'W' using the gradient descent for number of iterations equals to epochs\n","  # should also return error history int the cariable error_hist.shape = (epochs,); error_hist[i] = mean square error after epoch i-1\n","  # should also print mean square error after each epoch/ iteration\n","  # lr = \"learning rate\" i.e. eta\n","  \n","  # Write your code here ----------\n","  \n","  # -------------------------------\n","\n","  return W, error_hist"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uLTxFIOgkdjJ","colab_type":"text"},"source":["### Now write a complete code using the function defined above to learn the model for following cases:"]},{"cell_type":"markdown","metadata":{"id":"eYW1AukM378a","colab_type":"text"},"source":["##### Learn **W** using linear algebra method and prints mean square error between actual y and predicted y. Use `y_pred = XW`. Also plot y_pred and y on different plots."]},{"cell_type":"code","metadata":{"id":"AIRs0jB-kOZU","colab_type":"code","colab":{}},"source":["# Write your code here ----------\n","  \n","# -------------------------------"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6kP77_sK4CpT","colab_type":"text"},"source":["##### Learn **W** using gradient descent method for following learning rates, `lr = [0.01, 0.001, 0.0001]` for **10 epochs**. Plot **MSE vs epochs** for each of them.  Also plot y_pred and y on different plots."]},{"cell_type":"code","metadata":{"id":"1bac27RT4G2H","colab_type":"code","colab":{}},"source":["# Write your code here ----------\n","  \n","# -------------------------------"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4zJO-LIvn6sD","colab_type":"text"},"source":["## Question 2: Image Classification in Tensorflow using Deep Learning\n","To check whether you are able to build a given neural network model in tensorflow or not. First we will build a fully connected NN model second we will build a CNN model."]},{"cell_type":"code","metadata":{"id":"7mynGfqRn24b","colab_type":"code","colab":{}},"source":["import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s8WKt-qY4agV","colab_type":"code","colab":{}},"source":["def plot_history(history):\n","  # function to plot accuracy vs epoch\n","\n","  plt.plot(history.history['accuracy'], label='accuracy')\n","  plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n","  plt.xlabel('Epoch')\n","  plt.ylabel('Accuracy')\n","  plt.legend(loc='lower right')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tCT9Kmhhn5I_","colab_type":"code","colab":{}},"source":["def load_data_cifar10_norm():\n","  # should return the normalised cifar10 dataset by loading it from tensorflow\n","  # link: https://www.tensorflow.org/api_docs/python/tf/keras/datasets/cifar10/\n","\n","  # Write your code here ----------\n","\n","  # -------------------------------\n","\n","  return x_train, y_train, x_test, y_test"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LDpHSTRPvS9t","colab_type":"text"},"source":["### Define a fully connected neural network model with following attributes:\n","\n","*   Total number of **hidden layers = 4**, all with **relu** activation\n","*   Number of neurons in **first hidden layer = 7200**\n","*   Number of neurons in **second hidden layer = 2304**\n","*   Number of neurons in **third hidden layer = 1024**\n","*   Number of neurons in **fourth hidden layer = 64**\n"]},{"cell_type":"code","metadata":{"id":"VYYQzIWnqU3t","colab_type":"code","colab":{}},"source":["def build_fc_model(input_shape=(32, 32, 3), num_class=10):\n","  # should return a sequential model defined based on the above attributes\n","  # do not compile the model\n","\n","  # Write your code here ----------\n","\n","  # -------------------------------\n","\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pdcQ2yqz1RYH","colab_type":"text"},"source":["### Define a CNN model with following attribute:\n","\n","*   Total number of **hidden layer = 4**\n","*   After every convolutional layer there must be a MaxPoolingLayer of size (2, 2)\n","*   Total number of convolutional layer = 3, all with **relu** activation.\n","    *    Number of filters in **first convolutional layer = 32**\n","    *    Number of filters in **second convolutional layer = 64**\n","    *    Number of filters in **third convolutional layer = 64**\n","*   After all convolutional layer flatten the output and use **dense layer of 64 neurons**\n","\n"]},{"cell_type":"code","metadata":{"id":"T00AYU3D3L1j","colab_type":"code","colab":{}},"source":["def build_cnn_model(input_shape=(32, 32, 3), num_class=10):\n","  # should return a sequential model defined based on the above attributes\n","  # do not compile the model\n","\n","  # Write your code here ----------\n","\n","  # -------------------------------\n","\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7SXXUeRp4Urq","colab_type":"text"},"source":["### Compile and train the fully connected neural network model using the above functions."]},{"cell_type":"code","metadata":{"id":"61_XiEUR3eV0","colab_type":"code","colab":{}},"source":["# Write your code here ----------\n","\n","# -------------------------------\n","\n","history = model.fit(x_train, y_train, epochs=10, batch_size=512,\n","                    validation_data=(x_test, y_test))\n","\n","plot_history(history)\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z_yHXGc47ENb","colab_type":"text"},"source":["### Compile and train the CNN model using the above functions."]},{"cell_type":"code","metadata":{"id":"aM9rueu97Gnq","colab_type":"code","colab":{}},"source":["# Write your code here ----------\n","\n","# -------------------------------\n","\n","history = model.fit(x_train, y_train, epochs=10, batch_size=512,\n","                    validation_data=(x_test, y_test))\n","\n","plot_history(history)\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nKwrtPcy750Q","colab_type":"text"},"source":["### What do you observe? Compare both the model by looking at their Accuracy vs Epoch plot and total numbers of trainable parameters."]},{"cell_type":"code","metadata":{"id":"Q2lFRCoL8N_b","colab_type":"code","colab":{}},"source":["print(\"Replace this with your observation\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NlX1GE9f84dN","colab_type":"text"},"source":["## Question 3: Image Classification in Tensorflow using Transfer Learning\n","In this we will again try to learn a classification model for **cifar10** but by using the concept of transfer learning. "]},{"cell_type":"markdown","metadata":{"id":"TMQs8VAJaiZc","colab_type":"text"},"source":["### Brief description on Transfer Learning:"]},{"cell_type":"markdown","metadata":{"id":"velsoC8-KP6B","colab_type":"text"},"source":["The idea behind transfer learning for image classification is that when you train a model on a very large image dataset like ImageNet, then this model can effectivly serve as generic model of visual world. If you remember, a closer look at every CNN model gives you an idea that every CNN model used to have some sets of convolutional layers followed by a dense layer and finally at last a classification (output) layer. So, here the convolutional layer somewhat act as feature mapping function which maps the input image to an different dimensional space. And finally at the end you apply dense layer to classify the images based on those extracted features. <br>\n","\n","**Inshort this what you do in a CNN model:**\n","![](https://github.com/bcs-iitk/BCS_Workshop_Apr_20/raw/master/Machine_Learning/Assignment/cnn_model.png)\n","\n","So what we will do in transfer learning is that we will use some already pre-trained model which are trained on ImageNet dataset. Will only use its learned convolutional layers as a feature mapping function. And finally will learn a fully connected neural network on those features to classify the images.\n"]},{"cell_type":"markdown","metadata":{"id":"203W4I0oMs5v","colab_type":"text"},"source":["### Attributes of Transfer Learning model to be build\n","\n","*   Pre-trained weights of VGG16 will be used as feature extracter\n","*   After this flatten the output and use dense layer of **64 neurons**\n","\n"]},{"cell_type":"code","metadata":{"id":"COUcSjSz9DtQ","colab_type":"code","colab":{}},"source":["import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.applications.vgg16 import preprocess_input, VGG16"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ylCRV_niMhxA","colab_type":"code","colab":{}},"source":["def plot_history(history):\n","  # function to plot accuracy vs epoch\n","\n","  plt.plot(history.history['accuracy'], label='accuracy')\n","  plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n","  plt.xlabel('Epoch')\n","  plt.ylabel('Accuracy')\n","  plt.legend(loc='lower right')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ijdwptetMmSL","colab_type":"code","colab":{}},"source":["def load_data_cifar10():\n","  # should return the normalised cifar10 dataset by loading it from tensorflow\n","  # link: https://www.tensorflow.org/api_docs/python/tf/keras/datasets/cifar10/\n","\n","  # Write your code here ----------\n","\n","  # -------------------------------\n","\n","  return preprocess_input(x_train), y_train, preprocess_input(x_test), y_test"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8kgkpJfwKhlR","colab_type":"code","colab":{}},"source":["def build_tl_model(num_class=10):\n","  # should return the ccombined model using the VGG16 conv layers as conv layers\n","  # and for fully connected layer part use the above attributes.\n","\n","  base_model = VGG16(input_shape=(32, 32, 3), include_top=False, weights='imagenet') # this is the conv layers from VGG16\n","  base_model.trainable = False # this ensures that while training the dense layers these weights don't get changed\n","\n","  model = tf.keras.models.Sequential([\n","    # Feature extractor \n","    base_model,\n","\n","    # Flatten and use the attribute given the question to build the dense part\n","    # Write your code here ----------\n","\n","    # -------------------------------\n","  ])\n","\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_-2kUilyPNJJ","colab_type":"text"},"source":["### Compile and train the model using above functions, use adam optimiser with learning rate = 0.001 and 0.0001"]},{"cell_type":"code","metadata":{"id":"6FzIIP7GPMOt","colab_type":"code","colab":{}},"source":["# Write your code here ----------\n","\n","# -------------------------------\n","\n","history = model.fit(x_train, y_train, epochs=10, batch_size=512,\n","                    validation_data=(x_test, y_test))\n","\n","plot_history(history)\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l0QMGbtcQKNx","colab_type":"text"},"source":["## Question 4: Reinforcement Learning\n","In this you have to implement and train an RL agent to find a path for a frozen lake problem. "]},{"cell_type":"markdown","metadata":{"id":"qH7ubidoNaEv","colab_type":"text"},"source":["### Frozen Lake Problem Description:"]},{"cell_type":"markdown","metadata":{"id":"LTCY_Ip1M9Qc","colab_type":"text"},"source":["> Imagine there is a frozen lake stretching from your home to your office; you have to walk on the frozen lake to reach your office. But oops! There are holes in the frozen lake so you have to be careful while walking on the frozen lake to avoid getting trapped in the holes. [[src](https://subscription.packtpub.com/book/big_data_and_business_intelligence/9781788836524/3/ch03lvl1sec32/solving-the-frozen-lake-problem)]\n","\n","![frozen-lake](https://static.packt-cdn.com/products/9781788836524/graphics/49f3e058-2f32-40e8-9992-b53d1f57d138.png)\n","\n","\n","Two task you have to do here:\n","\n","*   Implement a frozen lake scenario given the inputs, number of holes (M) and size of the lake (N) (Assume the lake is square). Starting point will be (0, 0) and goal will be to reach at (N-1, N-1)\n","*   Implemenat Q-learning method to learn a path from start to goal.\n","*   Use the following reward scheme: 50 points on reaching the goal, -50 points on stepping on a hole.\n","\n","#### Q-learning\n","Recall from the lecture video that `Q[state, action]` gives you an action state pair to get an optimal policy. Recall the Q-Loss from the lecture video i.e:\n","> $E = ||r + \\gamma \\cdot \\max_{a'} Q(s', a') - Q(s, a)||^2$\n","\n","Use gradient descent to minimise $E$ and work out a learning rule for $Q(s, a)$. \n","> Take $\\max_{a'} Q(s', a')$ and $r$ to be independent of $Q(s, a)$.\n"]},{"cell_type":"markdown","metadata":{"id":"pbkIHLK7NFEw","colab_type":"text"},"source":["### Defining important functions"]},{"cell_type":"code","metadata":{"id":"QnnNULcYQNRj","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import copy"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n9vGeSBZEG-r","colab_type":"code","colab":{}},"source":["ActionMap = ['Up', 'Right', 'Down', 'Left']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"izQzYoXBHVgr","colab_type":"code","colab":{}},"source":["def get_board(N, M):\n","  # should return an N x N size frozen lake - board with M randomle placed holes.\n","  # use 'S' representation for starting point\n","  # use 'G' representation for goal point\n","  # use 'H' representation for holes\n","  # use 'F' for frozen lakes\n","  # use 'C' for displaying agents current position on the board.\n","  # Refer the representation from the image shown above\n","\n","  # Write your code here ----------\n","\n","  # -------------------------------\n","\n","  return board"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nu6PW4KhIZH7","colab_type":"code","colab":{}},"source":["def get_reward(board, N, M):\n","  # should return an N x N size reward table for the generated frozen lake scenario\n","  # use 50 reward for 'G' point\n","  # use -50 reward for 'H' point\n","  # o for rest.\n","\n","  # Write your code here ----------\n","\n","  # -------------------------------\n","\n","  return reward"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B1ueYhO8Ecnh","colab_type":"code","colab":{}},"source":["class FrozenLake:\n","  def __init__(self, N, M):\n","    # Recall python class, this function is called when you first initialise the class\n","    # Should intialise the board and reward table based on the reward scheme\n","    # Select M numbers of holes randomly\n","\n","    self.board = get_board(N, M)\n","    self.init_board = copy.deepcopy(self.board)\n","    self.reward = get_reward(self.board, N, M)\n","    self.state = (0, 0)\n","    self.finish = 0\n","    self.N = N\n","\n","\n","  def reset(self):\n","    # should reset the env with board to initial state\n","    # hint: set self.state at 0, 0 and use self.init_board to reset self.board\n","\n","    # Write your code here ----------\n","\n","    # -------------------------------\n","    self.finish = 0\n","\n","    return self.state\n","  \n","  def step(self, action):\n","    # ===== Action Table =========\n","    #     0 -- UP\n","    #     1 -- RIGHT\n","    #     2 -- DOWN\n","    #     3 -- LEFT\n","    # perform the given action and get update the  self.state, get reward, and update the self.board according to new state\n","    # update the self.board means update the new position with 'C' and replace previous position with {'S', 'F', 'G'} which is actually there according to the self.init_board\n","\n","    # Write your code here ----------\n","\n","    # -------------------------------\n","    \n","    # status to check if you reached your goal\n","    if self.state == (N-1, N-1):\n","        self.finish = 1\n","        \n","    return self.state, reward, self.finish\n","  \n","  def get_random_action(self):\n","    # ===== Action Table =========\n","    #     0 -- UP\n","    #     1 -- RIGHT\n","    #     2 -- DOWN\n","    #     3 -- LEFT\n","    # should return a possible random action out of the four\n","    # hint: note that when you are around the corner or sides of the board not all four action will be available for you\n","\n","    # Write your code here ----------\n","\n","    # -------------------------------\n","\n","    return action    \n","      \n","  def display(self):\n","    print(self.board)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oizARLSBNMxB","colab_type":"text"},"source":["### Environment creation and learning"]},{"cell_type":"code","metadata":{"id":"yGXRU7ImRnT6","colab_type":"code","colab":{}},"source":["def explore_exploit(env, Q, state, episode):\n","  # Notice that if you always select your new action based on maximum Q-value you will never get to see any new path right?\n","  # You have to explore the environment to know new paths\n","  # Write your code here to randomly select whether you want to explore or exploit\n","  # The probability of exploration should be exp(-episode*5e-4)\n","  # for exploration get some random action\n","  # for exploitation get action based on max Q value\n","\n","  # Write your code here ----------\n","\n","  # -------------------------------\n","\n","  return action"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"N6ym5P3-LxOz","colab_type":"code","colab":{}},"source":["def init_env_and_learn(N=6, M=12, gamma=0.8, lr=0.8):\n","  # gamma: gamma param of total discounted reward\n","  # lr: learning rate for Q updates\n","  # N = grid size of frozen lake wil be N x N\n","  # M = Number of holes\n","  # returns env, Q-function, rewards\n","\n","  env = FrozenLake(N, M)\n","  Q = np.zeros((N, N, 4))\n","\n","  total_episodes = 3000 # i.e. the number of times your RL agent will run through the board.\n","  max_steps = N*N*3 # maximum number of steps to perform\n","\n","  rewards = []\n","  for episode in range(total_episodes):\n","    state = env.reset()\n","    total_rewards = 0\n","\n","    for step in range(max_steps):\n","      action = explore_exploit(env, Q, state, episode)\n","\n","      # Write your code here ----------------------------------------------------------\n","      # Should perform the action get reward, new_state, finish status and update the Q value\n","\n","\n","      reward = '...' # replace these with your values\n","      finish = '...' # replace these with your values\n","      new_state = '...' # replace these with your values\n","      # -------------------------------------------------------------------------------\n","\n","      total_rewards += reward\n","      state = new_state\n","      \n","      if finish == 1: \n","          break\n","\n","    rewards.append(total_rewards)\n","\n","  return env, Q, rewards"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6z8EuJ6sXCTK","colab_type":"code","colab":{}},"source":["def travel_path(env, Q):\n","  # write a function to display a sequence of path performed using the learned Q-values\n","  # show initial and final frozen lake board \n","  # to perform an action at a state simply take max of Q at that state\n","\n","  # Write your code here ----------\n","\n","  # -------------------------------\n","\n","  return"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ios3sB8ZYDTN","colab_type":"text"},"source":["### Use N = 6, M = 10 and learn the models for following sets of gamma and lr:\n","\n","*   `(gamma, lr) = (0.8, 0.8)`\n","*   `(gamma, lr) = (0.95, 0.8)`\n","*   `(gamma, lr) = (0.6, 0.8)`\n","*   `(gamma, lr) = (0.8, 0.95)`\n","*   `(gamma, lr) = (0.8, 0.1)`\n","\n","Plot rewards vs episode for each of them and compare.\n","\n"]},{"cell_type":"code","metadata":{"id":"1BB8d1_3MhsL","colab_type":"code","colab":{}},"source":["# Write your code here ----------\n","\n","# -------------------------------\n","\n","print(\"Replace this with your observation\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yI5oHjVbZkIW","colab_type":"text"},"source":["### Use N = 6, M = 10 and learn a models with (gamma, lr) = (0.8, 0.8)\n","After learning the model, display a path traveled from source to goal."]},{"cell_type":"code","metadata":{"id":"RtDOaUEeMi-0","colab_type":"code","colab":{}},"source":["# Write your code here ----------\n","\n","# -------------------------------"],"execution_count":0,"outputs":[]}]}